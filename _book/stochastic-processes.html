<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Stochastic processes | Risk Modelling and Survival Analysis</title>
  <meta name="description" content="A modified version of the book on Risk Modelling and Survival Analysis, with additional notes and examples." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Stochastic processes | Risk Modelling and Survival Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A modified version of the book on Risk Modelling and Survival Analysis, with additional notes and examples." />
  <meta name="github-repo" content="priyam0k/CS2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Stochastic processes | Risk Modelling and Survival Analysis" />
  
  <meta name="twitter:description" content="A modified version of the book on Risk Modelling and Survival Analysis, with additional notes and examples." />
  

<meta name="author" content="Priyam" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="time-series.html"/>
<link rel="next" href="markov-chains.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Risk Modelling and Survival Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#motivation"><i class="fa fa-check"></i>Motivation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="r-setup.html"><a href="r-setup.html"><i class="fa fa-check"></i><b>1</b> R Setup</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-setup.html"><a href="r-setup.html#preparing-your-environment"><i class="fa fa-check"></i><b>1.1</b> Preparing your environment</a></li>
<li class="chapter" data-level="1.2" data-path="r-setup.html"><a href="r-setup.html#basic-interations-with-r"><i class="fa fa-check"></i><b>1.2</b> Basic interations with R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="loss-distributions.html"><a href="loss-distributions.html"><i class="fa fa-check"></i><b>2</b> Loss distributions</a>
<ul>
<li class="chapter" data-level="" data-path="loss-distributions.html"><a href="loss-distributions.html#objectives-loss-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="loss-distributions.html"><a href="loss-distributions.html#theory-loss-distributions"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="loss-distributions.html"><a href="loss-distributions.html#practice-loss-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="compound-loss-distributions.html"><a href="compound-loss-distributions.html"><i class="fa fa-check"></i><b>3</b> Compound loss distributions</a>
<ul>
<li class="chapter" data-level="" data-path="compound-loss-distributions.html"><a href="compound-loss-distributions.html#objectives-compound-loss-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="compound-loss-distributions.html"><a href="compound-loss-distributions.html#theory-compound-loss-distributions"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="3.0.1" data-path="compound-loss-distributions.html"><a href="compound-loss-distributions.html#chapter-compound-loss-distributions"><i class="fa fa-check"></i><b>3.0.1</b> <strong>Chapter: Compound Loss Distributions</strong></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="compound-loss-distributions.html"><a href="compound-loss-distributions.html#practice-compound-loss-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="copulas.html"><a href="copulas.html"><i class="fa fa-check"></i><b>4</b> Copulas</a>
<ul>
<li class="chapter" data-level="" data-path="copulas.html"><a href="copulas.html#objectives-copulas"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="copulas.html"><a href="copulas.html#theory-copulas"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="copulas.html"><a href="copulas.html#chapter-copulas-modelling-dependency-structures"><i class="fa fa-check"></i><b>4.0.1</b> <strong>Chapter: Copulas – Modelling Dependency Structures</strong></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="copulas.html"><a href="copulas.html#practice-copulas"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html"><i class="fa fa-check"></i><b>5</b> Extreme value theory</a>
<ul>
<li class="chapter" data-level="" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html#objectives-evt"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html#theory-evt"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="5.0.1" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html#chapter-16-extreme-value-theory"><i class="fa fa-check"></i><b>5.0.1</b> Chapter 16: Extreme Value Theory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html#practice-evt"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>6</b> Time series</a>
<ul>
<li class="chapter" data-level="" data-path="time-series.html"><a href="time-series.html#objectives-time-series"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="6.1" data-path="time-series.html"><a href="time-series.html#theory-time-series"><i class="fa fa-check"></i><b>6.1</b> Theory</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="time-series.html"><a href="time-series.html#time-series-a-deep-dive-for-cs2-actuarial-professionals"><i class="fa fa-check"></i><b>6.1.1</b> Time Series: A Deep Dive for CS2 Actuarial Professionals</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="time-series.html"><a href="time-series.html#practice-time-series"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>7</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="" data-path="stochastic-processes.html"><a href="stochastic-processes.html#objectives-stochastic-processes"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="stochastic-processes.html"><a href="stochastic-processes.html#theory-stochastic-processes"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="7.0.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#chapter-1-stochastic-processes"><i class="fa fa-check"></i><b>7.0.1</b> Chapter 1: Stochastic Processes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="stochastic-processes.html"><a href="stochastic-processes.html#practice-stochastic-processes"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>8</b> Markov chains</a>
<ul>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#objectives-markov-chains"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#theory-markov-chains"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="8.1" data-path="markov-chains.html"><a href="markov-chains.html#features-of-a-markov-chain-model"><i class="fa fa-check"></i><b>8.1</b> Features of a Markov chain model</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chains.html"><a href="markov-chains.html#chapman-kolmogorov-equations"><i class="fa fa-check"></i><b>8.2</b> Chapman-Kolmogorov equations</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chains.html"><a href="markov-chains.html#stationary-distribution-for-a-markov-chain"><i class="fa fa-check"></i><b>8.3</b> Stationary distribution for a Markov chain</a></li>
<li class="chapter" data-level="8.4" data-path="markov-chains.html"><a href="markov-chains.html#frequency-based-experience-rating"><i class="fa fa-check"></i><b>8.4</b> Frequency based experience rating</a></li>
<li class="chapter" data-level="8.5" data-path="markov-chains.html"><a href="markov-chains.html#time-inhomogeneous-markov-chain-model"><i class="fa fa-check"></i><b>8.5</b> Time-inhomogeneous Markov chain model</a></li>
<li class="chapter" data-level="8.6" data-path="markov-chains.html"><a href="markov-chains.html#markov-chains-in-modelling"><i class="fa fa-check"></i><b>8.6</b> Markov chains in modelling</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="markov-chains.html"><a href="markov-chains.html#simulating-a-markov-chain"><i class="fa fa-check"></i><b>8.6.1</b> Simulating a Markov chain</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#practice-markov-chains"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="markov-processes.html"><a href="markov-processes.html"><i class="fa fa-check"></i><b>9</b> Markov processes</a>
<ul>
<li class="chapter" data-level="" data-path="markov-processes.html"><a href="markov-processes.html#objectives-09"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="markov-processes.html"><a href="markov-processes.html#theory-09"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="9.1" data-path="markov-processes.html"><a href="markov-processes.html#features-of-a-markov-process-model"><i class="fa fa-check"></i><b>9.1</b> Features of a Markov process model</a></li>
<li class="chapter" data-level="9.2" data-path="markov-processes.html"><a href="markov-processes.html#poisson-process"><i class="fa fa-check"></i><b>9.2</b> Poisson process</a></li>
<li class="chapter" data-level="9.3" data-path="markov-processes.html"><a href="markov-processes.html#kolmogorov-equations-for-a-markov-process"><i class="fa fa-check"></i><b>9.3</b> Kolmogorov equations for a Markov process</a></li>
<li class="chapter" data-level="9.4" data-path="markov-processes.html"><a href="markov-processes.html#solving-kolmogorv-equations"><i class="fa fa-check"></i><b>9.4</b> Solving Kolmogorv equations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="markov-processes.html"><a href="markov-processes.html#simple-cases"><i class="fa fa-check"></i><b>9.4.1</b> Simple cases</a></li>
<li class="chapter" data-level="9.4.2" data-path="markov-processes.html"><a href="markov-processes.html#more-general-cases"><i class="fa fa-check"></i><b>9.4.2</b> More general cases</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="markov-processes.html"><a href="markov-processes.html#sickness-and-marriage-models"><i class="fa fa-check"></i><b>9.5</b> Sickness and marriage models</a></li>
<li class="chapter" data-level="9.6" data-path="markov-processes.html"><a href="markov-processes.html#markov-jump-process"><i class="fa fa-check"></i><b>9.6</b> Markov jump process</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="markov-processes.html"><a href="markov-processes.html#simulating-a-markov-jump-process"><i class="fa fa-check"></i><b>9.6.1</b> Simulating a Markov jump process</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-processes.html"><a href="markov-processes.html#practice-09"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="survival-models.html"><a href="survival-models.html"><i class="fa fa-check"></i><b>10</b> Survival models</a></li>
<li class="chapter" data-level="11" data-path="lifetime-distributions.html"><a href="lifetime-distributions.html"><i class="fa fa-check"></i><b>11</b> Lifetime distributions</a></li>
<li class="chapter" data-level="12" data-path="transition-intensities.html"><a href="transition-intensities.html"><i class="fa fa-check"></i><b>12</b> Estimating transition intensities</a></li>
<li class="chapter" data-level="13" data-path="graduation.html"><a href="graduation.html"><i class="fa fa-check"></i><b>13</b> Graduation</a></li>
<li class="chapter" data-level="14" data-path="mortality-projection.html"><a href="mortality-projection.html"><i class="fa fa-check"></i><b>14</b> Mortality projection</a></li>
<li class="chapter" data-level="15" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>15</b> Machine learning</a>
<ul>
<li class="chapter" data-level="" data-path="machine-learning.html"><a href="machine-learning.html#objectives-15"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="machine-learning.html"><a href="machine-learning.html#theory-15"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="15.1" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-topics"><i class="fa fa-check"></i><b>15.1</b> Machine learning topics</a></li>
<li class="chapter" data-level="15.2" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-from-data"><i class="fa fa-check"></i><b>15.2</b> Machine learning from data</a></li>
<li class="chapter" data-level="15.3" data-path="machine-learning.html"><a href="machine-learning.html#supervised-machine-learning"><i class="fa fa-check"></i><b>15.3</b> Supervised machine learning</a></li>
<li class="chapter" data-level="15.4" data-path="machine-learning.html"><a href="machine-learning.html#unsupervised-machine-learning"><i class="fa fa-check"></i><b>15.4</b> Unsupervised machine learning</a></li>
<li class="chapter" data-level="15.5" data-path="machine-learning.html"><a href="machine-learning.html#penalised-regression"><i class="fa fa-check"></i><b>15.5</b> Penalised regression</a></li>
<li class="chapter" data-level="15.6" data-path="machine-learning.html"><a href="machine-learning.html#decision-trees"><i class="fa fa-check"></i><b>15.6</b> Decision trees</a></li>
<li class="chapter" data-level="15.7" data-path="machine-learning.html"><a href="machine-learning.html#perspectives-of-non-actuarial-professionals"><i class="fa fa-check"></i><b>15.7</b> Perspectives of non-actuarial professionals</a></li>
<li class="chapter" data-level="" data-path="machine-learning.html"><a href="machine-learning.html#practice-15"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="divider"></li>
<li>Adapted by <a href="https://github.com/priyam0k">Priyam</a> from the original by <a href="https://github.com/agarbiak" target="blank">Alex Garbiak</a>.</li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Risk Modelling and Survival Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastic-processes" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Stochastic processes<a href="stochastic-processes.html#stochastic-processes" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objectives-stochastic-processes" class="section level2 unnumbered hasAnchor">
<h2>Learning Objectives<a href="stochastic-processes.html#objectives-stochastic-processes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Define in general terms a stochastic process and in particular a counting process.</li>
<li>Classify a stochastic process.</li>
<li>Describe possible applications of mixed processes.</li>
<li>Explain what is meant by the Markov property in the context of a stochastic process and in terms of filtrations.</li>
</ol>
</div>
<div id="theory-stochastic-processes" class="section level2 unnumbered hasAnchor">
<h2>Theory<a href="stochastic-processes.html#theory-stochastic-processes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="chapter-1-stochastic-processes" class="section level3 hasAnchor" number="7.0.1">
<h3><span class="header-section-number">7.0.1</span> Chapter 1: Stochastic Processes<a href="stochastic-processes.html#chapter-1-stochastic-processes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This chapter lays the essential groundwork for understanding random phenomena that evolve over time, which is fundamental to actuarial work. We’ll define what these processes are, how to classify them, explore their applications, and critically, understand the pivotal “Markov property”.</p>
<hr />
<div id="define-in-general-terms-a-stochastic-process-and-in-particular-a-counting-process.-28-29-3.1.1" class="section level4 hasAnchor" number="7.0.1.1">
<h4><span class="header-section-number">7.0.1.1</span> 1. Define in general terms a stochastic process and in particular a counting process. [28, 29, 3.1.1]<a href="stochastic-processes.html#define-in-general-terms-a-stochastic-process-and-in-particular-a-counting-process.-28-29-3.1.1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>At its core, a <strong>stochastic process</strong> is a mathematical model designed to represent a random phenomenon that changes or evolves over time. Unlike a single random variable that describes a static random event, a stochastic process is a <em>collection</em> or <em>family</em> of random variables. Each random variable in this collection is indexed by a subscript, typically representing time, such that <span class="math inline">\(X_t\)</span> models the value of the process at time <span class="math inline">\(t\)</span>. The process is formally denoted as <span class="math inline">\(\{X_t : t \in J\}\)</span>.</p>
<p>To fully define a stochastic process, you need to specify two key components:</p>
<ul>
<li><strong>Time Set (or Time Domain), J</strong>: This is the set of all points in time at which the value of the process can be observed or changes can occur. The time set can be either <strong>discrete</strong> (e.g., observations taken annually or daily) or <strong>continuous</strong> (e.g., changes occurring at any instant). For instance, a time series typically has a discrete time set.</li>
<li><strong>State Space, S</strong>: This refers to the comprehensive set of all possible values that any of the random variables (<span class="math inline">\(X_t\)</span>) within the stochastic process can take. Like the time set, the state space can be either <strong>discrete</strong> (e.g., whole numbers, categories) or <strong>continuous</strong> (e.g., any real number within a range). While the state space encompasses all possible values, for specific random variables in the set, some values might have a zero probability of occurring.</li>
</ul>
<p>A <strong>sample path</strong> is a single, joint realisation or trajectory of the random variables <span class="math inline">\(X_t\)</span> for all <span class="math inline">\(t\)</span> in the time set <span class="math inline">\(J\)</span>. Think of it as one specific sequence of observed values over time that the random phenomenon could take.</p>
<p>Now, let’s narrow our focus to a specific type: a <strong>counting process</strong>. A counting process, denoted <span class="math inline">\(X(t)\)</span>, is a stochastic process that operates in either discrete or continuous time. Its defining characteristics are:
* Its state space <span class="math inline">\(S\)</span> is restricted to the collection of natural numbers <span class="math inline">\(\{0, 1, 2, ...\}\)</span>.
* <span class="math inline">\(X(t)\)</span> is a non-decreasing function of <span class="math inline">\(t\)</span>. This means the count can only increase or stay the same; it can never decrease.
* It typically starts at <span class="math inline">\(X(0) = 0\)</span>.</p>
<p>A prime example of a counting process in actuarial science is the <strong>number of claims arising from a portfolio of policies up to time <span class="math inline">\(t\)</span></strong>. The Poisson process, which we’ll discuss further, is a classic example of a continuous-time counting process.</p>
<hr />
</div>
<div id="classify-a-stochastic-process.-28-29-3.1.2" class="section level4 hasAnchor" number="7.0.1.2">
<h4><span class="header-section-number">7.0.1.2</span> 2. Classify a stochastic process. [28, 29, 3.1.2]<a href="stochastic-processes.html#classify-a-stochastic-process.-28-29-3.1.2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The fundamental classification of a stochastic process stems from whether its <strong>time set</strong> and <strong>state space</strong> are discrete or continuous. This gives rise to a four-way classification system, as shown in the table:</p>
<table>
<colgroup>
<col width="18%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead>
<tr>
<th align="left">Time Set</th>
<th align="left">State Space: Discrete</th>
<th align="left">State Space: Continuous</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>Discrete</strong></td>
<td align="left">(1) Discrete Time, Discrete State</td>
<td align="left">(2) Discrete Time, Continuous State</td>
</tr>
<tr>
<td align="left"><strong>Continuous</strong></td>
<td align="left">(3) Continuous Time, Discrete State</td>
<td align="left">(4) Continuous Time, Continuous State</td>
</tr>
</tbody>
</table>
<p>Let’s explore each category with actuarial applications:</p>
<ol style="list-style-type: decimal">
<li><strong>Discrete Time, Discrete State Space</strong>:
<ul>
<li><strong>Description:</strong> Both observations occur at specific, separated points in time (e.g., annually, monthly) and the process can only take on distinct, countable values (e.g., integers, categories).</li>
<li><strong>Examples of Statistical Models:</strong> Markov chains, simple random walks, and discrete-time white noise processes with discrete state spaces.</li>
<li><strong>Actuarial Application:</strong> A prominent example is a <strong>no claims discount (NCD) system</strong> in motor insurance. Here, the discrete random variable <span class="math inline">\(X_t\)</span> represents the discount level (e.g., 0%, 25%, 40%, 60%) received by a policyholder in year <span class="math inline">\(t\)</span>. Changes in discount level happen at discrete time steps (e.g., policy renewal annually).</li>
</ul></li>
<li><strong>Discrete Time, Continuous State Space</strong>:
<ul>
<li><strong>Description:</strong> Observations occur at discrete time points, but the values the process can take are continuous (e.g., real numbers).</li>
<li><strong>Examples of Statistical Models:</strong> General random walks, time series, and white noise processes with continuous state spaces.</li>
<li><strong>Actuarial Application:</strong> Modelling the <strong>cumulative claim amount from a portfolio of insurance policies at the end of each month</strong>. Other relevant applications include the daily closing price of the FTSE100 index, or the share price of a company at the end of each trading day.</li>
</ul></li>
<li><strong>Continuous Time, Discrete State Space</strong>:
<ul>
<li><strong>Description:</strong> The process can change its value at any instant in time, but the values it can take are distinct and countable.</li>
<li><strong>Examples of Statistical Models:</strong> Markov jump processes (including the Poisson process as a special case), and counting processes with continuous time sets.</li>
<li><strong>Actuarial Application:</strong> A <strong>health, sickness, death model</strong>. Here, the discrete random variable <span class="math inline">\(X_t\)</span> takes values like ‘healthy’, ‘sick’, or ‘dead’ for any time <span class="math inline">\(t \ge 0\)</span>. Transitions between these states can occur at any moment, not just fixed intervals. Another common use is in modeling <strong>claims arriving at an insurance company</strong> via a Poisson process.</li>
</ul></li>
<li><strong>Continuous Time, Continuous State Space</strong>:
<ul>
<li><strong>Description:</strong> Changes can occur at any moment in time, and the values the process can take are continuous.</li>
<li><strong>Examples of Statistical Models:</strong> Brownian motion, diffusion processes, and compound Poisson processes with continuous state spaces. (Note: Brownian motion and diffusion processes are typically covered in Subject CM2).</li>
<li><strong>Actuarial Application:</strong> Modelling the <strong>cumulative claim amount from a portfolio of policies up to time <span class="math inline">\(t\)</span></strong>, where individual claim amounts are continuous random variables. The share price of a company at any given time <span class="math inline">\(t\)</span> since trading began is another example.</li>
</ul></li>
</ol>
<hr />
</div>
<div id="describe-possible-applications-of-mixed-processes.-28-29-3.1.3" class="section level4 hasAnchor" number="7.0.1.3">
<h4><span class="header-section-number">7.0.1.3</span> 3. Describe possible applications of mixed processes. [28, 29, 3.1.3]<a href="stochastic-processes.html#describe-possible-applications-of-mixed-processes.-28-29-3.1.3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A <strong>stochastic process of mixed type</strong> is one that exhibits characteristics from both continuous and discrete time processes. Specifically, it operates in continuous time, meaning changes can happen at any instant, but it also features <strong>predetermined discrete points in time</strong> where the value of the process can change.</p>
<p>This dual nature makes mixed processes particularly useful for modelling real-world scenarios where both continuous and discrete events interact.</p>
<p>A key application in actuarial science is modelling the <strong>number of contributors to a pension scheme</strong>. In such a model:
* Deaths can occur at <strong>any time</strong> (continuous time aspect), leading to a continuous decrement from the number of contributors.
* However, members may only be allowed to retire on specific <strong>birthdays</strong> (e.g., between ages 60 and 65). These retirement ages represent predetermined discrete points in time where a change in the number of contributors can occur.</p>
<p>This combination of continuous events (deaths) and discrete, scheduled events (retirements) makes it a classic example of a mixed-type stochastic process.</p>
<hr />
</div>
<div id="explain-what-is-meant-by-the-markov-property-in-the-context-of-a-stochastic-process-and-in-terms-of-filtrations.-28-29-3.1.4" class="section level4 hasAnchor" number="7.0.1.4">
<h4><span class="header-section-number">7.0.1.4</span> 4. Explain what is meant by the Markov property in the context of a stochastic process and in terms of filtrations. [28, 29, 3.1.4]<a href="stochastic-processes.html#explain-what-is-meant-by-the-markov-property-in-the-context-of-a-stochastic-process-and-in-terms-of-filtrations.-28-29-3.1.4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <strong>Markov property</strong> is a fundamental simplifying assumption for many stochastic processes, stating that the future development of a process depends <em>only</em> on its <strong>present state</strong>, and is entirely independent of its <strong>past history</strong>. This means that once you know the current state of the process, any additional knowledge about how it reached that state is irrelevant for predicting its future.</p>
<p>Formally, for a stochastic process <span class="math inline">\(\{X_t : t \in J\}\)</span>, the Markov property can be stated as:
<span class="math inline">\(P[X_t \in A | X_{s_1}=x_1, X_{s_2}=x_2, ..., X_{s_n}=x_n, X_s=x] = P[X_t \in A | X_s=x]\)</span>
for all times <span class="math inline">\(s_1 &lt; s_2 &lt; ... &lt; s_n &lt; s &lt; t\)</span> in <span class="math inline">\(J\)</span>, all states <span class="math inline">\(x_1, x_2, ..., x_n\)</span> and <span class="math inline">\(x\)</span> in <span class="math inline">\(S\)</span>, and all subsets <span class="math inline">\(A\)</span> of <span class="math inline">\(S\)</span>. The use of subsets <span class="math inline">\(A \subseteq S\)</span> is necessary to cover continuous state spaces where the probability of <span class="math inline">\(X_t\)</span> taking a <em>particular</em> value is zero.</p>
<p><strong>Filtrations</strong> provide a formal way to describe the information available about a stochastic process up to a certain time. For any stochastic process <span class="math inline">\(X_t\)</span>, there are underlying structures:
* A <strong>sample space <span class="math inline">\(\Omega\)</span></strong>: Each outcome <span class="math inline">\(\omega\)</span> in <span class="math inline">\(\Omega\)</span> determines a unique sample path <span class="math inline">\((X_t(\omega))\)</span>.
* A set of <strong>events <span class="math inline">\(\mathcal{F}\)</span></strong>: A collection of subsets of <span class="math inline">\(\Omega\)</span> to which probabilities can be assigned.
* For each time <span class="math inline">\(t\)</span>, a smaller collection of events <span class="math inline">\(\mathcal{F}_t \subseteq \mathcal{F}\)</span>: This set comprises all events whose truth or falsity is known by time <span class="math inline">\(t\)</span>. In simpler terms, an event <span class="math inline">\(A\)</span> belongs to <span class="math inline">\(\mathcal{F}_t\)</span> if its occurrence depends solely on the process’s values up to time <span class="math inline">\(t\)</span>, i.e., <span class="math inline">\(\{X_s : 0 \le s \le t\}\)</span>.</p>
<p>As time <span class="math inline">\(t\)</span> increases, the information available generally expands, meaning <span class="math inline">\(\mathcal{F}_t \subseteq \mathcal{F}_u\)</span> for <span class="math inline">\(t \le u\)</span>. This collection of sets <span class="math inline">\(\{\mathcal{F}_t : t \ge 0\}\)</span> is known as the <strong>(natural) filtration associated with the stochastic process</strong>. It encapsulates the “history” or “information gained by observing the process” up to time <span class="math inline">\(t\)</span>.</p>
<p>In terms of filtrations, the Markov property can be concisely stated as:
<span class="math inline">\(P[X_t \in A | \mathcal{F}_s] = P[X_t \in A | X_s]\)</span> for all <span class="math inline">\(t \ge s \ge 0\)</span>. This reiterates that the future distribution of the process, given all past information up to time <span class="math inline">\(s\)</span> (<span class="math inline">\(\mathcal{F}_s\)</span>), depends only on the current state <span class="math inline">\(X_s\)</span>.</p>
<p><strong>Key relationship: Independent increments implies Markov property</strong>
A crucial result is that any stochastic process with <strong>independent increments</strong> also possesses the Markov property.
* <strong>Independent increments</strong> means that for any <span class="math inline">\(t\)</span> and any <span class="math inline">\(u &gt; 0\)</span>, the increment <span class="math inline">\(X_{t+u} - X_t\)</span> is independent of all the past values of the process up to and including time <span class="math inline">\(t\)</span> (i.e., <span class="math inline">\(\{X_s : 0 \le s \le t\}\)</span>).
* The proof essentially leverages this independence: by knowing the current state <span class="math inline">\(X_s\)</span>, the future increment <span class="math inline">\(X_t - X_s\)</span> is independent of previous history (<span class="math inline">\(X_{s_1}, ..., X_{s_n}\)</span>), thus the future state <span class="math inline">\(X_t\)</span> only depends on <span class="math inline">\(X_s\)</span>.</p>
<p>Let’s look at how specific processes exhibit (or don’t exhibit) the Markov property:</p>
<ul>
<li><strong>White Noise Process</strong>: A sequence of independent random variables. This process trivially satisfies the Markov property because its future development is <em>completely</em> independent of its past. Each observation is independent of all previous observations, so knowing the “current” state provides no more information than knowing nothing about the past (beyond the current state itself).</li>
<li><strong>General Random Walk</strong>: Defined as <span class="math inline">\(X_n = Y_1 + Y_2 + ... + Y_n\)</span>, where <span class="math inline">\(Y_j\)</span> are independent and identically distributed random variables. Since the increments (<span class="math inline">\(X_n - X_{n-1} = Y_n\)</span>) are independent, a general random walk <em>has</em> the Markov property. However, it is <em>not</em> stationary, as its mean and variance typically increase linearly with time.
<ul>
<li>A <strong>simple random walk</strong> is a special case where <span class="math inline">\(Y_j\)</span> can only take values +1 or -1. A <strong>simple symmetric random walk</strong> is a simple random walk where <span class="math inline">\(P(Y_j=1) = P(Y_j=-1) = 0.5\)</span>.</li>
</ul></li>
<li><strong>Poisson Process</strong>: A continuous-time counting process with independent, stationary Poisson-distributed increments. Because it has independent increments, a Poisson process <em>satisfies the Markov property</em>. It is <em>not</em> stationary, as its mean and variance increase linearly with time.</li>
<li><strong>Compound Poisson Process</strong>: Defined as <span class="math inline">\(X_t = \sum_{j=1}^{N_t} Y_j\)</span>, where <span class="math inline">\(N_t\)</span> is a Poisson process and <span class="math inline">\(Y_j\)</span> are independent and identically distributed random variables. This process also has independent increments, and therefore <em>has the Markov property</em>. Similar to the Poisson process, it is <em>not</em> weakly stationary, as its expected value and variance change over time.</li>
</ul>
<p>This foundational understanding of stochastic processes, their classifications, and particularly the Markov property, is crucial as we progress to more specific models like Markov Chains and Markov Jump Processes in subsequent chapters. Keep practicing, and you’ll master CS2 in no time!</p>
</div>
</div>
</div>
<div id="practice-stochastic-processes" class="section level2 unnumbered hasAnchor">
<h2><code>R</code> Practice<a href="stochastic-processes.html#practice-stochastic-processes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>TO ADD R EXAMPLE ABOUT STOCHASTIC PROCESSES HERE</strong></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="time-series.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="markov-chains.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["twitter", "linkedin"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/priyam0k/CS2/edit/main/07-stochastic-processes.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
